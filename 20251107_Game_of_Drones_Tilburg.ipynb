{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fecaf05",
   "metadata": {},
   "source": [
    "# Game of Drones on a Graph - Real Map Analysis (Tilburg)\n",
    "This notebook contains a structured analysis of a **Stackelberg game** between a drone and a jammer, using a realistic graph extracted from OpenStreetMap (OSM) centered on **Tilburg, Netherlands**.\n",
    "\n",
    "The notebook follows the implementation described in Section V.A of the associated research paper.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Imports\n",
    "2. Graph Processing and Map Construction\n",
    "3. Game Elements (Routes, Threat, Payoff)\n",
    "4. Stackelberg Game Logic\n",
    "5. Results and Visualizations\n",
    "6. Conclusions and Further Work\n",
    "\n",
    "## Change Log:\n",
    "20251107_0946 Initial upload on GitHub/nlcircle \n",
    "20251107_0949 First minor change and push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5140b",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8e4e39-c897-4714-945f-3fa1b74b5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from shapely.geometry import Point\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# graph constants\n",
    "tilburg_bbox = [5.07, 51.554, 5.1, 51.566]   # Tilburg, area around MindLabs\n",
    "epsilon = 20                                 # distance in meters for node integration\n",
    "\n",
    "# route model\n",
    "start_nodes = [[51.553608, 5.069024, 'Kromhout park'],\n",
    "               [51.564203, 5.066040, 'RingbaanWest'],\n",
    "               [51.565511, 5.100537, 'RingbaanOost'],\n",
    "               [51.553628, 5.097518, 'Galjoenstraat'],\n",
    "               [51.5669465636276, 5.080646900855821, 'Wilhelminapark'],\n",
    "               [51.5631993195584, 5.107997457873059, 'Bossscheweg'],\n",
    "               [51.55419099433148, 5.085804497908121, 'Willemsplein'],\n",
    "               [51.56571632960617, 5.089517797871289, 'BesterdRing']]\n",
    "target = [51.560931, 5.086468, 'Mindlabs']\n",
    "nr_routes = 2500                              # k-factor for 'k_shortest_paths'\n",
    "\n",
    "# threat model\n",
    "jammer_nodes = [880]\n",
    "probs = [0.4, 0.2, 0.05]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b5529",
   "metadata": {},
   "source": [
    "## 2. Graph Processing and Map Construction\n",
    "This section defines the `OSMGraphProcessor` class for downloading, preprocessing, and displaying the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1fd7d4f-bd96-4e3f-ba66-fa9879568833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare functions to be called later\n",
    "class OSMGraphProcessor:\n",
    "    def __init__(self, bounding_box, epsilon=20):\n",
    "        \"\"\"\n",
    "        Initialize the OSMGraphProcessor with a bounding box and epsilon (in meters).\n",
    "        \"\"\"\n",
    "        self.north = bounding_box[3]\n",
    "        self.south = bounding_box[1]\n",
    "        self.east = bounding_box[2]\n",
    "        self.west = bounding_box[0]\n",
    "        self.epsilon = epsilon  # Distance threshold in meters for node consolidation\n",
    "        self.graph = None\n",
    "\n",
    "    def create_graph(self):\n",
    "        \"\"\"\n",
    "        Create an initial graph from OSM data and preprocess it.\n",
    "        \"\"\"\n",
    "        print(\"Downloading OSM graph...\")\n",
    "        bbox = [self.west, self.south, self.east, self.north]\n",
    "        self.graph = ox.graph_from_bbox(bbox, network_type='walk')\n",
    "        print(\"Graph downloaded.\")\n",
    "\n",
    "        # Convert to undirected\n",
    "        print(\"Converting to undirected...\")\n",
    "        self.graph = self.graph.to_undirected()\n",
    "\n",
    "        # Simplify the graph\n",
    "        #print(\"Simplifying graph...\")\n",
    "        #self.graph = ox.simplify_graph(self.graph)\n",
    "\n",
    "        # Consolidate nodes using DBSCAN\n",
    "        self._consolidate_nodes()\n",
    "\n",
    "        # Ensure all edges have a 'length' in meters\n",
    "        print(\"Assigning edge lengths and initializing edge risk...\")\n",
    "        self._assign_edge_attributes()\n",
    "\n",
    "    def _consolidate_nodes(self):\n",
    "        \"\"\"\n",
    "        Use DBSCAN clustering to consolidate nodes closer than epsilon meters.\n",
    "        \"\"\"\n",
    "        coords = np.array([[data['y'], data['x']] for node, data in self.graph.nodes(data=True)])\n",
    "        eps_rad = self.epsilon / 6371000  # convert meters to radians for haversine\n",
    "        clustering = DBSCAN(eps=eps_rad, min_samples=1, algorithm='ball_tree', metric='haversine')\n",
    "        coords_rad = np.radians(coords)\n",
    "        labels = clustering.fit_predict(coords_rad)\n",
    "\n",
    "        label_to_node = {}\n",
    "        mapping = {}\n",
    "        for idx, (node, data) in enumerate(self.graph.nodes(data=True)):\n",
    "            label = labels[idx]\n",
    "            if label not in label_to_node:\n",
    "                label_to_node[label] = node\n",
    "            mapping[node] = label_to_node[label]\n",
    "\n",
    "        # Relabel and consolidate\n",
    "        print(\"Relabeling consolidated nodes...\")\n",
    "        self.graph = nx.relabel_nodes(self.graph, mapping, copy=False)\n",
    "        self.graph = nx.convert_node_labels_to_integers(self.graph)  # optional\n",
    "\n",
    "    def _assign_edge_attributes(self):\n",
    "        \"\"\"\n",
    "        Assign 'length' and 'edge_risk' to all edges.\n",
    "        \"\"\"\n",
    "        for u, v, key, data in self.graph.edges(keys=True, data=True):\n",
    "            if 'length' not in data:\n",
    "                # compute great-circle distance manually\n",
    "                lat1, lon1 = self.graph.nodes[u]['y'], self.graph.nodes[u]['x']\n",
    "                lat2, lon2 = self.graph.nodes[v]['y'], self.graph.nodes[v]['x']\n",
    "                data['length'] = ox.distance.great_circle_vec(lat1, lon1, lat2, lon2)\n",
    "            data['edge_risk'] = 0.0\n",
    "\n",
    "    def plot_graph(self):\n",
    "        \"\"\"\n",
    "        Plot the graph with geographic projection.\n",
    "        \"\"\"\n",
    "        print(\"Plotting graph geographically...\")\n",
    "        fig, ax = ox.plot_graph(self.graph, figsize=(14,10),\n",
    "                                node_size=10, node_color='maroon', \n",
    "                                edge_color='gray', bgcolor='k')\n",
    "\n",
    "    def plot_stats(self):\n",
    "        \"\"\"\n",
    "        Plot histogram of edge lengths and basic graph statistics.\n",
    "        \"\"\"\n",
    "        lengths = [data['length'] for u, v, data in self.graph.edges(data=True)]\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.hist(lengths, bins=50, color='blue', alpha=0.7)\n",
    "        plt.title('Edge Length Distribution')\n",
    "        plt.xlabel('Length (meters)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Graph stats:\")\n",
    "        print(f\"Number of nodes: {self.graph.number_of_nodes()}\")\n",
    "        print(f\"Number of edges: {self.graph.number_of_edges()}\")\n",
    "        print(f\"Average degree: {sum(dict(self.graph.degree()).values()) / self.graph.number_of_nodes():.2f}\")\n",
    "        print(f\"Average edge length: {np.mean(lengths):.2f} meters\")\n",
    "\n",
    "    def get_graph(self):\n",
    "        \"\"\"\n",
    "        Return the final processed graph.\n",
    "        \"\"\"\n",
    "        return self.graph\n",
    "\n",
    "\n",
    "class GoDGraph():\n",
    "\n",
    "    def __init__(self, bbox, epsilon):\n",
    "        G_intake = OSMGraphProcessor(bbox, epsilon)\n",
    "        G_intake.create_graph()\n",
    "        #G_intake.plot_graph()\n",
    "       \n",
    "        # now extract the actual graph from G_intake and read in as 'G':\n",
    "        self.G = G_intake.get_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7efba33",
   "metadata": {},
   "source": [
    "## 3. Game Elements\n",
    "Here we define the core components of the game model:\n",
    "- `RoutesModel`: generates K shortest paths\n",
    "- `ThreatModel`: sets jammer nodes and affects edge risks\n",
    "- `PayoffMatrix`: evaluates the trade-offs between path length and threat exposure.\n",
    "Each is encapsulated into a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ca1a6a-6bfd-4dd7-88cf-e5880564630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class routes_model():\n",
    "    \"\"\"\n",
    "    Class to hold and handle route objects. Receives a graph G, start nodes, \n",
    "    target node and number of shortest paths to calculate.\n",
    "    Stores:\n",
    "        - self.routes: route nodes and route-wide stats (length, risk)\n",
    "        - self.edge_data: edge-level info per route\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, G, start_nodes, target_node, nr_of_routes):\n",
    "        self.graph = G\n",
    "        self.start_nodes = start_nodes\n",
    "        self.target_node = target_node\n",
    "        self.nr_routes = nr_of_routes\n",
    "\n",
    "        # Get routes and edge data\n",
    "        self.get_new_routes()\n",
    "        self.get_edge_data()\n",
    "        self._get_routes_length()\n",
    "\n",
    "        print(\"routes_model instantiated ...\")\n",
    "\n",
    "    def get_new_routes(self):\n",
    "        \"\"\"\n",
    "        Find k-shortest routes from each start node to the target.\n",
    "        \"\"\"\n",
    "        self.routes = dict()\n",
    "\n",
    "        for start_index, start in enumerate(self.start_nodes):\n",
    "            k_routes = list(ox.k_shortest_paths(self.graph,\n",
    "                                                start, self.target_node,\n",
    "                                                self.nr_routes,\n",
    "                                                weight='length'))\n",
    "\n",
    "            for route_index, route in enumerate(k_routes):\n",
    "                route_name = f\"Start{start_index}-Route{route_index}\"\n",
    "                self.routes[route_name] = {\n",
    "                    'nodes': route, 'length': 0, 'risk': 0\n",
    "                }\n",
    "\n",
    "    def get_edge_data(self):\n",
    "        \"\"\"\n",
    "        For each route, extract per-edge information: from, to, length, risk.\n",
    "        Result is saved in self.edge_data.\n",
    "        \"\"\"\n",
    "        self.edge_data = dict()\n",
    "\n",
    "        for route_key, route_info in self.routes.items():\n",
    "            node_path = route_info['nodes']\n",
    "            route_edges = dict()\n",
    "\n",
    "            for i, (u, v) in enumerate(zip(node_path[:-1], node_path[1:])):\n",
    "                if self.graph.is_multigraph():\n",
    "                    edge_dict = self.graph.get_edge_data(u, v)\n",
    "                    length = edge_dict[0]['length']\n",
    "                else:\n",
    "                    length = np.nan\n",
    "\n",
    "                route_edges[i] = {\n",
    "                    'from': u,\n",
    "                    'to': v,\n",
    "                    'length': length,\n",
    "                    'risk': 0 }\n",
    "\n",
    "            self.edge_data[route_key] = route_edges\n",
    "\n",
    "    def _get_routes_length(self):\n",
    "        \"\"\"Take all routes, calculate total length from route_model.edge_data and store\n",
    "        in route_model.routes[key]['length']\"\"\"\n",
    "\n",
    "        for route_key in self.routes:\n",
    "            route_length = 0\n",
    "            for edge in self.edge_data[route_key]:\n",
    "                route_length += self.edge_data[route_key][edge]['length']\n",
    "            self.routes[route_key]['length'] = route_length\n",
    "\n",
    "\n",
    "    \n",
    "    def _reset_route_model(self):\n",
    "        \"\"\"\n",
    "        Reset the model: regenerate all routes and edge data.\n",
    "        \"\"\"\n",
    "        self.get_new_routes()\n",
    "        self.get_edge_data()\n",
    "        print(f\"Route | Reset of routes and edge_data, nr of new routes is {len(self.routes)}\")\n",
    "\n",
    "    def update_edges_with_jammer_risk(self, threat):\n",
    "        \"\"\"\n",
    "        Update edge risks based on external threat object.\n",
    "        \"\"\"\n",
    "        for route_key in self.edge_data:\n",
    "            for edge_idx, edge in self.edge_data[route_key].items():\n",
    "                u, v = edge['from'], edge['to']\n",
    "                base_risk = edge['risk']\n",
    "\n",
    "                if u in threat.threat_nodes and v in threat.threat_nodes:\n",
    "                    delta = abs(threat.threat_nodes[u] - threat.threat_nodes[v])\n",
    "                    match delta:\n",
    "                        case 0:\n",
    "                            risk_rank = threat.threat_nodes[u] + 1\n",
    "                        case 1:\n",
    "                            risk_rank = min(threat.threat_nodes[u], threat.threat_nodes[v])\n",
    "                        case _:\n",
    "                            risk_rank = 99\n",
    "\n",
    "                    edge['risk'] = threat.probs[risk_rank] if risk_rank < 3 else base_risk\n",
    "\n",
    "        print(\"Route | Edge data for new routes updated with threat data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a436703-2ae9-417a-aa99-055678239ca0",
   "metadata": {},
   "source": [
    "## 3.2 - Class threat_model\n",
    "\n",
    "Define the class for the jammer, capturing the threat model for this game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed32ab0d-90e0-48af-bbe1-ef13a6353590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class threat_model():\n",
    "\n",
    "    def __init__(self, G, jnodes, probs):\n",
    "        self.G = G                                # undirected graph from area\n",
    "        \n",
    "        self.jnodes = np.array(jnodes)            # array with jammer locations\n",
    "        self.union_jammer_nodes = dict()          # create empty union bin for jammer nodes\n",
    "        \n",
    "        self.probs = [0.4, 0.2, 0.05]             # lethality probabilities per edge\n",
    "\n",
    "        print(f\"Threat | Model created, available nodes={self.jnodes}, probabilities={self.probs}\")\n",
    "\n",
    "    \n",
    "    def set_threat_nodes(self, jammer_node):\n",
    "        \"\"\"\n",
    "        Find set of affected nodes (threat_nodes) for a specific jammer_node\n",
    "        \"\"\"\n",
    "        self.threat_nodes = nx.single_source_shortest_path_length(self.G, \n",
    "                                                                  jammer_node, \n",
    "                                                                  cutoff=len(self.probs))\n",
    "        #print(f\"Threat Model | Threat Nodes - {len(self.threat_nodes)} threat nodes found, jammer at {jammer_node}\")\n",
    "\n",
    "\n",
    "    def collect_jammer_nodes(self, route_model):\n",
    "        \"\"\"\n",
    "        Use previously found routes from self.routes to build a union set of nodes where the jammer could\n",
    "        be placed. For each node, its normalised presence in the route set is recorded.\n",
    "\n",
    "        Note - a jammer doesn't have to be on the route to cause damage, nodes outside the route are not\n",
    "        yet included in this union. How to find those ?\n",
    "        \"\"\"\n",
    "        \n",
    "        node_union = dict()\n",
    "        nr_routes = len(route_model.routes)\n",
    "        \n",
    "        for route in route_model.routes:\n",
    "            for index in np.arange(len(route)):\n",
    "                print(route, index)\n",
    "                if route[index] in node_union.keys():\n",
    "                    node_union[route[index]] += 1\n",
    "                else:\n",
    "                    node_union[route[index]] = 1\n",
    "\n",
    "        print(f\"Threat | the union of the first {len(route_model.routes)} routes is {self.union_jammer_nodes}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a9cca-6adf-4d17-9885-421560e0eac0",
   "metadata": {},
   "source": [
    "## 3.3 Class payoff_matrix\n",
    "\n",
    "Contains two dictionaries, one for the value pairs (risk, length) and one for the lexicographic payoff \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{payoff} = - \\gamma R(p,j) - L(p)\n",
    "\\end{equation}\n",
    "\n",
    "with \n",
    "\n",
    "\\begin{equation}\n",
    "\\gamma \\geq \\frac{\\text{Max Length}}{\\delta \\text{Prob}}\n",
    "\\end{equation}\n",
    "as per the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbc5779-0b9a-4814-9b0b-09431abf50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, Tuple, Any, List\n",
    "\n",
    "\n",
    "\n",
    "class PayoffMatrix:\n",
    "    def __init__(self, gamma=5000 / 0.01, length_scale=2000):\n",
    "        self.value_matrix = {}   # {(route_index, jammer_node): {\"length\": ..., \"risk\": ...}}\n",
    "        self.payoff_matrix = {}  # {(route_index, jammer_node): payoff}\n",
    "        self.gamma = gamma\n",
    "        self.normalisation = gamma * 1 + length_scale\n",
    "        print(\"PayoffMatrix | initialized.\")\n",
    "\n",
    "    def compute(self, graph, route_model, jammer_nodes, threat_model):\n",
    "        route_model.get_edge_data()  # Ensure edge_data is updated\n",
    "        num_routes = len(route_model.edge_data)\n",
    "\n",
    "        for r_idx in range(num_routes):\n",
    "            print(r_idx)\n",
    "            original_edges = route_model.edge_data[r_idx].copy()\n",
    "\n",
    "            for j_node in jammer_nodes:\n",
    "                updated_edges = self._update_risks(original_edges.copy(), j_node, threat_model)\n",
    "\n",
    "                total_length = 0\n",
    "                survival_prob = 1\n",
    "\n",
    "                for edge in updated_edges.values():\n",
    "                    total_length += edge[\"length\"]\n",
    "                    survival_prob *= (1 - edge[\"risk\"])\n",
    "\n",
    "                risk = 1 - survival_prob\n",
    "                self.value_matrix[(r_idx, j_node)] = {\"length\": total_length, \"risk\": risk}\n",
    "\n",
    "                # Convert to single payoff\n",
    "                payoff = (-self.gamma * risk - total_length) / self.normalisation\n",
    "                self.payoff_matrix[(r_idx, j_node)] = payoff\n",
    "\n",
    "    def _update_risks(self, edge_dict, jammer_node, threat_model):\n",
    "        threat_model.set_threat_nodes(jammer_node)\n",
    "\n",
    "        for edge_key, edge_data in edge_dict.items():\n",
    "            u, v = edge_data[\"from\"], edge_data[\"to\"]\n",
    "            rank_u = threat_model.threat_nodes.get(u, -1)\n",
    "            rank_v = threat_model.threat_nodes.get(v, -1)\n",
    "\n",
    "            if rank_u >= 0 and rank_v >= 0:\n",
    "                delta = abs(rank_u - rank_v)\n",
    "                if delta == 0:\n",
    "                    rank = rank_u\n",
    "                elif delta == 1:\n",
    "                    rank = min(rank_u, rank_v)\n",
    "                else:\n",
    "                    rank = 9999\n",
    "                edge_data[\"risk\"] = threat_model.probs[rank] if rank < len(threat_model.probs) else 0\n",
    "            else:\n",
    "                edge_data[\"risk\"] = 0\n",
    "\n",
    "        return edge_dict\n",
    "\n",
    "    def save_to_txt(self, prefix=\"GoDonAGraph\"):\n",
    "        with open(f\"{prefix}_value.txt\", 'w') as vf:\n",
    "            for (r, j), val in self.value_matrix.items():\n",
    "                vf.write(f\"Route {r}, jammer at {j} - dist={val['length']:.2f}, risk={val['risk']:.4f}\\n\")\n",
    "\n",
    "        with open(f\"{prefix}_payoff.txt\", 'w') as pf:\n",
    "            for (r, j), val in self.payoff_matrix.items():\n",
    "                pf.write(f\"Route {r}, jammer at {j} - payoff={val:.3f}\\n\")\n",
    "\n",
    "        print(f\"PayoffMatrix | files '{prefix}_value.txt' and '{prefix}_payoff.txt' written.\")\n",
    "\n",
    "    def export_to_json(self, filename: str = \"payoff_matrix_export.json\"):\n",
    "        \"\"\"\n",
    "        Exports all relevant instance attributes (gamma, normalisation, value_matrix, payoff_matrix)\n",
    "        to a JSON file. Tuple keys are converted to strings for serialization.\n",
    "        \"\"\"\n",
    "        print(f\"PayoffMatrix | Starting JSON export to '{filename}'...\")\n",
    "\n",
    "        # 1. Convert tuple keys in matrices to strings\n",
    "        def convert_matrix_keys(matrix: Dict[Tuple[int, int], Any]) -> Dict[str, Any]:\n",
    "            string_keyed_matrix = {}\n",
    "            for (r_idx, j_node), data in matrix.items():\n",
    "                # Format: \"route_R_jammer_J\"\n",
    "                key_str = f\"route_{r_idx}_jammer_{j_node}\"\n",
    "                string_keyed_matrix[key_str] = data\n",
    "            return string_keyed_matrix\n",
    "\n",
    "        # 2. Compile all data into a single dictionary\n",
    "        export_data = {\n",
    "            \"gamma\": self.gamma,\n",
    "            \"length_scale\": self.length_scale,\n",
    "            \"normalisation\": self.normalisation,\n",
    "            \"value_matrix\": convert_matrix_keys(self.value_matrix),\n",
    "            \"payoff_matrix\": convert_matrix_keys(self.payoff_matrix),\n",
    "        }\n",
    "\n",
    "        # 3. Write data to JSON file\n",
    "        try:\n",
    "            with open(filename, 'w') as f:\n",
    "                # Use indent=4 for a human-readable format\n",
    "                json.dump(export_data, f, indent=4)\n",
    "            print(f\"PayoffMatrix | Successfully exported data to '{filename}'\")\n",
    "        except IOError as e:\n",
    "            print(f\"PayoffMatrix | Error writing to file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805953cf-c282-47f5-b2aa-b6fafafc0323",
   "metadata": {},
   "source": [
    "# 4 - Game of Drone on a Graph\n",
    "\n",
    "This section handles the overall game definition based on the previous classes and contains a separate section on the analysis.\n",
    "\n",
    "## 4.1 Class GameOfDronesOnAGraph\n",
    "\n",
    "This is the main game class, which includes the threat_model, the route_model and the graph. From this class, the various types of analysis are handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f50c807-ffee-4441-9132-e6071ce8ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameOfDronesOnAGraph():\n",
    "\n",
    "    def __init__(self, start_set, target_coord, nr_routes,\n",
    "                 bbox, epsilon,\n",
    "                 jammer_nodes, probs):\n",
    "        \"\"\"GoD environment, defining entire game and support classes.\"\"\"\n",
    "        # set generic parameters for the game\n",
    "        self.V = dict()                # value (length,risk) for each route/jammer node pair\n",
    "\n",
    "        # create and plot the graph first:\n",
    "        self.bbox = bbox   \n",
    "        self.G = GoDGraph(self.bbox, epsilon).G\n",
    "        self.fig, self.ax = ox.plot_graph(self.G, figsize=(12, 10), node_size=5, show=False, close=False)\n",
    "        if self.G:\n",
    "            print(f\"GameOfDronesOnAGraph - Graph G generated {self.G}\")\n",
    "\n",
    "        # set parameters for obtaining 'nr_of_routes' routes\n",
    "        start_nodes = self._get_start_nodes_from_coordinates(start_set)\n",
    "        target_node = ox.distance.nearest_nodes(self.G, target_coord[1], target_coord[0])\n",
    "        print(f\"GameOfDronesOnAGraph - Start: {start_nodes}, Target: {target_node}\")\n",
    "\n",
    "        # create routes and plot these in the existing graph:\n",
    "        self.R = routes_model(self.G, start_nodes, target_node, nr_routes)\n",
    "        print(f\"GameOfDronesOnAGraph - Routes generated {self.R}\")\n",
    "        self._plot_routes_from_routemodel_on_graph()\n",
    "\n",
    "        # set jammer nodes:\n",
    "        self.T = threat_model(self.G, jammer_nodes, probs)\n",
    "        print(f\"GameOfDronesOnAGraph - Threat model loaded {self.T}\")\n",
    "\n",
    "        # create payoff matrix\n",
    "        self.PM = PayoffMatrix()\n",
    "        print(f\"GameOfDronesOnAGraph - PayOff matrix {self.PM}\")\n",
    "\n",
    "\n",
    "        # report results to user\n",
    "        print(f\"GameOfDrones | Start from node {self.R.start_nodes} to target on node {self.R.target_node}\")\n",
    "\n",
    "\n",
    "    def _get_start_nodes_from_coordinates(self, start_set):\n",
    "        return([ox.distance.nearest_nodes(self.G, start[1], start[0]) for start in start_set])\n",
    "\n",
    "\n",
    "  \n",
    "    def plot_nodes(self, coordinates, color):\n",
    "        \"\"\" Find nearest node to a given (lat, lon) and plot it on the graph. \"\"\"\n",
    "    \n",
    "        cmap = mpl.colormaps.get_cmap('plasma')\n",
    "        nodes = [ox.distance.nearest_nodes(self.G, c[1], c[0], return_dist=False) for c in coordinates ]\n",
    "        for index, n in enumerate(nodes):\n",
    "            self.ax.scatter(self.G.nodes[n]['x'], \n",
    "                            self.G.nodes[n]['y'],\n",
    "                            color=color,\n",
    "                            s=50,\n",
    "                            label=coordinates[index][2],\n",
    "                            zorder=5)\n",
    "\n",
    "        self.ax.legend()\n",
    "        display(self.fig)\n",
    "        plt.savefig('GoD Tilburg area incl start nodes and target node.png')\n",
    " \n",
    "    def _plot_routes_from_routemodel_on_graph(self):\n",
    "        for start in self.R.routes:\n",
    "            self.plot_route_on_graph(self.G, self.R.routes[start]['nodes'])\n",
    "        display(self.fig)\n",
    "\n",
    "    \n",
    "    def plot_route_on_graph(self, G, route):\n",
    "        \"\"\"Plot a specified route (list of node IDs) on the shared ax.\"\"\"\n",
    "        # Extract coordinates\n",
    "        x = [G.nodes[node]['x'] for node in route]\n",
    "        y = [G.nodes[node]['y'] for node in route]\n",
    "        \n",
    "        # Plot the route on the existing axis\n",
    "        self.ax.plot(x, y, color='yellow', linewidth=3, zorder=4)\n",
    "    \n",
    "        # Optionally highlight start and end\n",
    "        self.ax.scatter(x[0], y[0], color='green', s=30, zorder=5)  # start node\n",
    "        self.ax.scatter(x[-1], y[-1], color='red', s=30, zorder=5)  # end node\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07dbbb-ca40-4566-badf-9e23d3e55e81",
   "metadata": {},
   "source": [
    "## Run the game\n",
    "\n",
    "The game is initiated with a set of start nodes, for instance the four corners of the bounding box. Once the GT class is instantiated, the four start nodes and the target node is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e42fc-0df1-48c8-a126-9b8cfbcab2c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GT = GameOfDronesOnAGraph(start_nodes, target, nr_routes, tilburg_bbox, epsilon, jammer_nodes, probs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba448a8-d1df-44ea-98ee-90f24779e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT.PM.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a786072-135b-4a78-b7e0-47dfd6cd5bca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Generate routes\n",
    "\n",
    "Use the defined start points to generate a number 'k' of routes from each point to the target. Plot these in varying colors, depending on their origin.\n",
    "\n",
    "The routes are returned in a dictionary 'total_routes', which can be addressed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "total_routes = \\text{{'start1': [[route1], [route2], ... [routek]], 'start2': [[route1], [route2], ... [routek]], ...}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "## Heatmap for total_routes\n",
    "\n",
    "With a sufficient number of routes generated, we produce a heat map of the graph, where the edges and nodes are displayed as function of the number of times they have been traversed.\n",
    "\n",
    "The function below allows coloring of these edges and nodes as well, but the resulting heatmap quickly becomes incomprehensible. For now, stick to the width of the edges and the size of the nodes to display more frequent usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115f98ef-8e28-4581-b7ee-02f1e0b25627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from collections import Counter\n",
    "\n",
    "def plot_node_edge_heatmap_scaled(G, R, figsize=(12, 10)):\n",
    "    \"\"\"\n",
    "    Plots a heatmap on graph G with:\n",
    "    - node color & size scaled by visitation frequency\n",
    "    - edge color & width scaled by traversal frequency\n",
    "\n",
    "    Parameters:\n",
    "        G: NetworkX graph\n",
    "        total_routes: dict[start_node] = list of paths (each path is a list of node IDs)\n",
    "        figsize: size of figure\n",
    "    \"\"\"\n",
    "\n",
    "    cmap = mpl.colormaps.get_cmap('jet')  #plasma, viridis, jet, gnuplot2\n",
    "\n",
    "    # Step 1: Flatten all routes into node visits and edge traversals\n",
    "    all_nodes = []\n",
    "    all_edges = []\n",
    "\n",
    "    route_keys = R.routes.keys()\n",
    "\n",
    "    for route_key in route_keys:\n",
    "        route = R.routes[route_key]['nodes']\n",
    "        \n",
    "        all_nodes.extend(route)\n",
    "\n",
    "        for i in range(len(route) - 1):\n",
    "            u, v = route[i], route[i + 1]\n",
    "            if G.has_edge(u, v):\n",
    "                all_edges.append((u, v))\n",
    "            elif G.has_edge(v, u):\n",
    "                all_edges.append((v, u))\n",
    "\n",
    "    # Step 2: Count frequencies\n",
    "    node_counts = Counter(all_nodes)\n",
    "    edge_counts = Counter(all_edges)\n",
    "\n",
    "    max_node_count = max(node_counts.values(), default=1)\n",
    "    total_node_visits = sum(node_counts.values())\n",
    "    \n",
    "    max_edge_count = max(edge_counts.values(), default=1)\n",
    "    total_edge_visits = sum(edge_counts.values())\n",
    "\n",
    "    # Step 3: Prepare node attributes\n",
    "    node_color = []\n",
    "    node_size = []\n",
    "    node_norm = []\n",
    "\n",
    "    for node in G.nodes:\n",
    "        count = node_counts.get(node, 0)\n",
    "        norm = count / total_node_visits if total_node_visits > 0 else 0\n",
    "        node_norm.append(norm)\n",
    "        #node_color.append(count)\n",
    "        node_color = 'black'\n",
    "        node_size.append(5 + 3000 * norm)  # adjustable scaling\n",
    "\n",
    "    # Step 4: Prepare edge attributes\n",
    "    edge_color = []\n",
    "    edge_width = []\n",
    "    edge_norm = []\n",
    "\n",
    "    for u, v in G.edges():\n",
    "        count = edge_counts.get((u, v), edge_counts.get((v, u), 0))\n",
    "        norm = count / total_edge_visits if total_edge_visits > 0 else 0\n",
    "        edge_norm.append(norm)\n",
    "        #edge_color.append(cmap(norm))             # RGBA color\n",
    "        if norm>0:\n",
    "            color='red'\n",
    "        else:\n",
    "            color='black'\n",
    "        edge_color.append(color)\n",
    "        edge_width.append(.5 + 250 * norm)        # linewidth range: [0.5, 5.0]\n",
    "\n",
    "    # Step 5: Plot\n",
    "    fig, ax = ox.plot_graph(\n",
    "        G,\n",
    "        node_color=node_color, node_size=node_size, node_zorder=2,\n",
    "        edge_linewidth=edge_width, edge_color=edge_color,\n",
    "        bgcolor='white',\n",
    "        show=False, close=False,\n",
    "        figsize=figsize\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return(node_counts, node_norm, edge_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590213f6-00b8-4567-b14a-aa57c52d59ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cnodes, Nnode, Nedge = plot_node_edge_heatmap_scaled(GT.G, GT.R, figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4145c-783d-4fe4-8db5-de90eb7d5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse the MC routes to find average, longest and shortest route in the entire set;\n",
    "\n",
    "tot_nodes = 0\n",
    "shortest_route = 100\n",
    "longest_route = 1\n",
    "count = 0\n",
    "\n",
    "for route in GT.R.routes:\n",
    "    length = len(GT.R.routes[route]['nodes'])\n",
    "    tot_nodes += length\n",
    "    shortest_route =  min(shortest_route, length)\n",
    "    longest_route = max(shortest_route, length)\n",
    "    count+=1\n",
    "\n",
    "avg_nodes_per_route = tot_nodes / count\n",
    "print(f\"The average nr of nodes per MC simulated route is {avg_nodes_per_route:2.1f}\")\n",
    "print(f\"    longest route: {longest_route}, shortest_route: {shortest_route}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7fc3b9-d551-4cd6-92a6-4f2b6dd4837b",
   "metadata": {},
   "source": [
    "## Node importance\n",
    "\n",
    "As the heatmap is based on a histogram of node usage across 20.000 routes through this relative small section of a real map, it serves as an indicator of the likelikhood that a node is part of a randomly chosen route. \n",
    "\n",
    "For a realistic game-theoretic approach, we need to limit the number of jammer nodes. The heatmap or the estimated probability density function for the nodes can serve as first order approach towards reduction of the total set of graph nodes to the jammer node set.\n",
    "\n",
    "In the next segment, we rank and filter the total set of node counts, based on their relative importance and a minimum value before a node can be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344c6ee-ae7b-4dca-b699-ced9f0294fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalised_node_importance(counter):\n",
    "    \"\"\"Plots the values from a counter, until reaching a minimum value (min_count),\n",
    "    with the node numbers on the x-axis\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort counter by value in descending order\n",
    "    sorted_items = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "    max_nodes = len(sorted_items)\n",
    "  \n",
    "    \n",
    "    # Extract labels and values\n",
    "    labels = [str(item[0]) for item in sorted_items[1:75]]  # Convert labels to strings if not already\n",
    "    values = [item[1] for item in sorted_items[1:75]]\n",
    "    max_value = len(GT.R.routes) \n",
    "    norm_values = [val/max_value for val in values]\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 8))  # Optional: adjust figure size\n",
    "    plt.bar(labels[:max_nodes], norm_values[:max_nodes], color='skyblue')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Node References')  # X-axis label\n",
    "    plt.ylabel('Normalised Values')  # Y-axis label\n",
    "    plt.title(f'Node importance ($N=75')  # Title\n",
    "    \n",
    "    # Rotate x-axis labels if needed (in case they are long)\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "    plt.show()\n",
    "\n",
    "    return(sorted_items)\n",
    "\n",
    "#sorted_nodes = plot_normalised_node_importance(Cnodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff16a29-d4ac-4ac2-8d88-2302904c5616",
   "metadata": {},
   "source": [
    "# Entropy for sorted nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d14c8-5b17-458f-af77-16f034c529d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "class RouteEntropyAnalyzer:\n",
    "    def __init__(self, G, routes):\n",
    "        self.G = G\n",
    "        self.routes = routes\n",
    "        self.node_counts = None\n",
    "        self.edge_counts = None\n",
    "        self.node_entropy = None\n",
    "        self.edge_entropy = None\n",
    "        self.node_entropy_max = None\n",
    "        self.edge_entropy_max = None\n",
    "        self.node_freq = None\n",
    "        self.edge_freq = None\n",
    "\n",
    "    def compute_node_entropy(self):\n",
    "        all_nodes = []\n",
    "        for r in self.routes.values():\n",
    "            all_nodes.extend(r[\"nodes\"])\n",
    "\n",
    "        self.node_counts = Counter(all_nodes)\n",
    "        total = sum(self.node_counts.values())\n",
    "        probs = np.array([count / total for count in self.node_counts.values()])\n",
    "        self.node_entropy = -np.sum(probs * np.log2(probs))\n",
    "\n",
    "        # Max entropy: log2 of number of unique nodes\n",
    "        support_size = len(self.node_counts)\n",
    "        self.node_entropy_max = np.log2(support_size)\n",
    "\n",
    "        \n",
    "        return self.node_entropy\n",
    "\n",
    "    def compute_edge_entropy(self):\n",
    "        all_edges = []\n",
    "        for r in self.routes.values():\n",
    "            nodes = r[\"nodes\"]\n",
    "            for i in range(len(nodes) - 1):\n",
    "                u, v = nodes[i], nodes[i + 1]\n",
    "                if self.G.has_edge(u, v):\n",
    "                    all_edges.append((u, v))\n",
    "                elif self.G.has_edge(v, u):\n",
    "                    all_edges.append((v, u))\n",
    "\n",
    "        self.edge_counts = Counter(all_edges)\n",
    "        total = sum(self.edge_counts.values())\n",
    "        probs = np.array([count / total for count in self.edge_counts.values()])\n",
    "        self.edge_entropy = -np.sum(probs * np.log2(probs))\n",
    "\n",
    "        # Max entropy: log2 of number of unique edges\n",
    "        support_size = len(self.edge_counts)\n",
    "        self.edge_entropy_max = np.log2(support_size)\n",
    "        return self.edge_entropy\n",
    "\n",
    "\n",
    "    def summarize_entropy(self):\n",
    "        print(\"===== Entropy Summary =====\")\n",
    "        print(f\"Node Entropy      H = {self.node_entropy:.4f} bits\")\n",
    "        print(f\"Max Node Entropy  H_max = {self.node_entropy_max:.4f} bits\")\n",
    "        print(f\"Relative Node Entropy = {100 * self.node_entropy / self.node_entropy_max:.2f}%\")\n",
    "        print()\n",
    "        print(f\"Edge Entropy      H = {self.edge_entropy:.4f} bits\")\n",
    "        print(f\"Max Edge Entropy  H_max = {self.edge_entropy_max:.4f} bits\")\n",
    "        print(f\"Relative Edge Entropy = {100 * self.edge_entropy / self.edge_entropy_max:.2f}%\")\n",
    "        print(\"============================\")\n",
    "\n",
    "    def plot_entropy_distributions(self, top_n=30):\n",
    "        total_nodes = sum(self.node_counts.values())\n",
    "        total_edges = sum(self.edge_counts.values())\n",
    "\n",
    "        sorted_nodes = sorted(self.node_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        sorted_edges = sorted(self.edge_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "        axs[0].bar([str(k) for k, v in sorted_nodes], [v/total_nodes for k, v in sorted_nodes], color=\"steelblue\")\n",
    "        axs[0].set_title(f\"Top Node Visit Frequencies (Total = {total_nodes})\")\n",
    "        axs[0].set_ylabel(\"Relative Frequency\")\n",
    "        axs[0].tick_params(axis='x', rotation=90)\n",
    "\n",
    "        axs[1].bar([f\"{u}-{v}\" for (u, v), c in sorted_edges], [c/total_edges for (u, v), c in sorted_edges], color=\"orange\")\n",
    "        axs[1].set_title(f\"Top Edge Traversal Frequencies (Total = {total_edges})\")\n",
    "        axs[1].set_ylabel(\"Relative Frequency\")\n",
    "        axs[1].tick_params(axis='x', rotation=90)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_jammer_candidates(self, top_k=10):\n",
    "        \"\"\"Returns the top-k most visited nodes as jammer node candidates\"\"\"\n",
    "        sorted_nodes = sorted(self.node_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        jammer_nodes = [node for node, count in sorted_nodes[:top_k]]\n",
    "        return jammer_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e083dbb-85aa-4a89-af91-d7edbe0028bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the RouteEntropyAnalyser, plot the entropy distributions and list the proposed jammer nodes.\n",
    "analyzer = RouteEntropyAnalyzer(GT.G, GT.R.routes)\n",
    "analyzer.compute_node_entropy()\n",
    "analyzer.compute_edge_entropy()\n",
    "analyzer.summarize_entropy()\n",
    "#analyzer.plot_entropy_distributions()\n",
    "jammer_nodes = analyzer.get_jammer_candidates(top_k=10)\n",
    "print(\"Suggested jammer node set:\", jammer_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc34bc9-12fd-4662-99c3-b15ec8301020",
   "metadata": {},
   "source": [
    "## Entropy weighing\n",
    "\n",
    "We end up with both node entropy and the entropy for edges. we use the node frequencies and edge frequencies to calculate a new 'score' for each node, based on the following formula (see paper for further explanation):\n",
    "\n",
    "\\begin{equation}\n",
    "    S(v) = \\alpha . P(v) + (1 - \\alpha) . \\sum_{u \\in N(v)} P(uv)\n",
    "\\end{equation}\n",
    "\n",
    "where $P(v$ is the node frequency, $N(v)$ is the neighborhood of node $v$ (so the set of adjacent nodes)) and $P(uv)$ the edge frequency for edge u-v.\n",
    "\n",
    "$S(v)$ is the node specific value which determines the ranking of nodes prior to inclusion in the jammer node set (nodes with highest $n$ score values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82dd3a-a336-4ca5-83b7-64a5051da3df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set alpha: weight of relative node importance\n",
    "alpha = 0.5\n",
    "\n",
    "# get relative node importance:\n",
    "node_freq = analyzer.node_counts\n",
    "total_node_freq = sum(node_freq.values())\n",
    "\n",
    "rel_node_imp = {\n",
    "    v: node_freq.get(v, 0) / total_node_freq\n",
    "    for v in GT.G.nodes()\n",
    "}\n",
    "\n",
    "\n",
    "# Normalized edge usage\n",
    "edge_freq = analyzer.edge_counts\n",
    "total_edge_freq = sum(analyzer.edge_counts.values())\n",
    "\n",
    "norm_edge_freq = {\n",
    "    e: edge_freq.get(e, edge_freq.get((e[1], e[0]), 0)) / total_edge_freq\n",
    "    for e in GT.G.edges()\n",
    "}\n",
    "\n",
    "# Score computation\n",
    "score_data = []\n",
    "for v in GT.G.nodes():\n",
    "    rni = rel_node_imp.get(v, 0.0)\n",
    "    neighbor_edges = list(GT.G.edges(v))\n",
    "    edge_vals = [norm_edge_freq.get((u, w), norm_edge_freq.get((w, u), 0.0)) for u, w in neighbor_edges]\n",
    "    nei = np.mean(edge_vals) if edge_vals else 0.0\n",
    "    score = alpha * rni + (1 - alpha) * nei\n",
    "    score_data.append((v, rni, nei, score))\n",
    "\n",
    "# Create and sort the score table\n",
    "df_scores = pd.DataFrame(score_data, columns=[\"Node\", \"RelNodeImportance\", \"MeanEdgeImportance\", \"Score\"])\n",
    "df_scores_sorted = df_scores.sort_values(by=\"Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top 10 nodes\n",
    "jammer_node_set = df_scores_sorted.head(10).to_string(index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d39c1a-dab9-455d-928f-db7092dac54a",
   "metadata": {},
   "source": [
    "## Reduce Routes for payoff matrix\n",
    "\n",
    "In previous sections, we have used a Monte Carlo approach to simulate a total of 20.000 routes from eight start positions to the target. These routes have been used to establish a priority over some nodes, which makes these elligible as jammer nodes (due to node importance considerations).\n",
    "\n",
    "To avoid an explosion of the payoff matrix, we need to reduce the routes to a number of 'representative routes' to demonstrate the principle of a sequential game on a real map. The following section deals with this process of reduction, aiming to establish a realistic and representative route set for the sequential game and thus payoff matrix.\n",
    "\n",
    "For our paper, we apply the Subgraph Strategy, where all routes are condensed to a subgraph arount the target T, under the assumption that regardless where the drone approaches from, any route will eventually converge to a smaller set of ingress routes when closer to the target. The next cell calculates the subgraph based on the 'reach' of the threat model (number of hops) and analyses the possible start nodes on the edges to define an entropy based ingress set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d14c38c-2aa7-43d6-9517-6f4aa22ab354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "class SubgraphGameOfDrones:\n",
    "    def __init__(self, G_full, target_node, k_hops, node_importance_dict, jammer_nodes, alpha_thresh):\n",
    "        self.G_full = G_full\n",
    "        self.target = target_node\n",
    "        self.k_hops = k_hops\n",
    "        self.node_importance = node_importance_dict\n",
    "        self.jammer_nodes = jammer_nodes\n",
    "        self.alpha = alpha_thresh\n",
    "\n",
    "        self.subgraph = None\n",
    "        self.start_nodes = []\n",
    "        self.routes = defaultdict(list)  # key: start node, value: list of paths\n",
    "        self.route_value_matrix = []\n",
    "\n",
    "    def create_subgraph(self):\n",
    "        nodes_within_k = nx.single_source_shortest_path_length(self.G_full, self.target, cutoff=self.k_hops)\n",
    "        self.subgraph = self.G_full.subgraph(nodes_within_k.keys()).copy()\n",
    "\n",
    "    def select_viable_start_nodes(self):\n",
    "        self.start_nodes = [n for n in self.subgraph.nodes if self.node_importance.get(n, 0) >= self.alpha \n",
    "                            and n != self.target \n",
    "                            if len(nx.shortest_path(self.subgraph, \n",
    "                                                    n, \n",
    "                                                    self.target, weight='length')) == 7 ]\n",
    "        #print(f\"Start nodes for alpha={self.alpha:2.4f} are {self.start_nodes}\")\n",
    "        \n",
    "\n",
    "    def generate_k_shortest_routes(self, k_per_start_node=100):\n",
    "        for s in self.start_nodes:\n",
    "            paths = list(ox.k_shortest_paths(self.subgraph, \n",
    "                                             orig=s, dest=self.target, \n",
    "                                             k=k_per_start_node, \n",
    "                                             weight='length'))\n",
    "            self.routes[s] = paths[:k_per_start_node]\n",
    "\n",
    "                \n",
    "\n",
    "    def _compute_risk(self, path, jammer_node, threat_model_obj):\n",
    "        threat_model_obj.set_threat_nodes(jammer_node)\n",
    "        affected_nodes = threat_model_obj.threat_nodes\n",
    "        probs = threat_model_obj.probs\n",
    "\n",
    "        prob_product = 1.0\n",
    "        for u, v in zip(path[:-1], path[1:]):\n",
    "            r1 = affected_nodes.get(u, None)\n",
    "            r2 = affected_nodes.get(v, None)\n",
    "            risk1 = probs[r1 - 1] if r1 and r1 <= len(probs) else 0.0\n",
    "            risk2 = probs[r2 - 1] if r2 and r2 <= len(probs) else 0.0\n",
    "            edge_risk = max(risk1, risk2)\n",
    "            prob_product *= (1 - edge_risk)\n",
    "        return 1 - prob_product\n",
    "\n",
    "\n",
    "    def compute_route_value_matrix(self, risk_model):\n",
    "        matrix = []\n",
    "        for s, paths in self.routes.items():\n",
    "            for path in paths:\n",
    "                length = sum(self.G_full[u][v][0].get('length', 1.0) for u, v in zip(path[:-1], path[1:]))\n",
    "                for jammer in self.jammer_nodes:\n",
    "                    risk = self._compute_risk(path, jammer, risk_model)\n",
    "                    matrix.append({\n",
    "                        'start': s,\n",
    "                        'path': path,\n",
    "                        'jammer': jammer,\n",
    "                        'risk': risk,\n",
    "                        'length': length\n",
    "                    })\n",
    "        self.route_value_matrix = matrix\n",
    "\n",
    "\n",
    "    def compute_lexicographic_payoff_matrix(self, gamma, battery_limit=None):\n",
    "        \"\"\"\n",
    "        Constructs the lexicographic payoff matrix:\n",
    "        For each route i and jammer j, stores the tuple (-risk, -length)\n",
    "        \"\"\"\n",
    "        # Step 1: identify unique routes and jammer nodes\n",
    "        unique_routes = []\n",
    "        route_index_map = {}\n",
    "        jammer_index_map = {}\n",
    "        index = 0\n",
    "\n",
    "        for entry in self.route_value_matrix:\n",
    "            path_tuple = tuple(entry['path'])\n",
    "            if path_tuple not in route_index_map:\n",
    "                route_index_map[path_tuple] = len(unique_routes)\n",
    "                unique_routes.append(path_tuple)\n",
    "            if entry['jammer'] not in jammer_index_map:\n",
    "                jammer_index_map[entry['jammer']] = len(jammer_index_map)\n",
    "\n",
    "        # Initialize empty matrix of size (#routes x #jammers)\n",
    "        m, n = len(unique_routes), len(jammer_index_map)\n",
    "        lex_payoff_matrix = [[None for _ in range(n)] for _ in range(m)]\n",
    "\n",
    "        # Fill the matrix\n",
    "        for entry in self.route_value_matrix:\n",
    "            path = tuple(entry['path'])\n",
    "            jammer = entry['jammer']\n",
    "            i = route_index_map[path]\n",
    "            j = jammer_index_map[jammer]\n",
    "            risk = entry['risk']\n",
    "            length = entry['length']\n",
    "\n",
    "            # Apply battery constraint (infeasible paths get -inf utility)\n",
    "            if battery_limit is not None and length > battery_limit:\n",
    "                lex_payoff_matrix[i][j] = (-float('inf'), -float('inf'))\n",
    "            else:\n",
    "                lex_payoff_matrix[i][j] = (-risk, -length)\n",
    "\n",
    "        # Save outputs\n",
    "        self.lex_payoff_matrix = lex_payoff_matrix\n",
    "        self.route_index_map = route_index_map\n",
    "        self.jammer_index_map = jammer_index_map\n",
    "        print(f\"Lexicographic payoff matrix created: {m} drone routes  {n} jammer nodes.\")\n",
    "\n",
    "\n",
    "    def compute_normalised_scalar_payoff_matrix(self, gamma=1.0, battery_limit=None):\n",
    "        \"\"\"\n",
    "        Constructs a scalar payoff matrix:\n",
    "        u(p, j) = -gamma * risk - length\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: identify unique routes and jammer nodes\n",
    "        unique_routes = []\n",
    "        route_index_map = {}\n",
    "        jammer_index_map = {}\n",
    "        index = 0\n",
    "\n",
    "        for entry in self.route_value_matrix:\n",
    "            path_tuple = tuple(entry['path'])\n",
    "            if path_tuple not in route_index_map:\n",
    "                route_index_map[path_tuple] = len(unique_routes)\n",
    "                unique_routes.append(path_tuple)\n",
    "            if entry['jammer'] not in jammer_index_map:\n",
    "                jammer_index_map[entry['jammer']] = len(jammer_index_map)\n",
    "\n",
    "        # Initialize empty matrix of size (#routes x #jammers)\n",
    "        m, n = len(unique_routes), len(jammer_index_map)\n",
    "        scalar_payoff_matrix = np.full((m, n), -np.inf)\n",
    "\n",
    "        # Fill the matrix\n",
    "        for entry in self.route_value_matrix:\n",
    "            path = tuple(entry['path'])\n",
    "            jammer = entry['jammer']\n",
    "            i = route_index_map[path]\n",
    "            j = jammer_index_map[jammer]\n",
    "            risk = entry['risk']\n",
    "            length = entry['length']\n",
    "\n",
    "            if battery_limit is not None and length > battery_limit:\n",
    "                scalar_payoff_matrix[i][j] = -np.inf\n",
    "            else:\n",
    "                scalar_payoff_matrix[i][j] = -gamma * risk - length\n",
    "\n",
    "        # Store results\n",
    "        self.normalised_scalar_payoff_matrix = scalar_payoff_matrix / (gamma + 1000)\n",
    "        self.route_index_map = route_index_map\n",
    "        self.jammer_index_map = jammer_index_map\n",
    "        print(f\"Scalar payoff matrix computed: {m} routes  {n} jammer nodes\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df72e5-98d3-4083-8a1b-6c9e9b692859",
   "metadata": {},
   "source": [
    "## Fig.12 Size of S for $\\alpha$ (rel. node importance)\n",
    "\n",
    "Based on the subgraph class, we can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34562414-5977-4a44-b44e-ab1eb9c546d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the number of shortest paths for each start node in the subgraph\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for alpha in np.linspace(0.015, 0, 50):\n",
    "    SG = SubgraphGameOfDrones(GT.G, \n",
    "                          target_node=518, k_hops=6, \n",
    "                          node_importance_dict=rel_node_imp, \n",
    "                          jammer_nodes=jammer_nodes, \n",
    "                          alpha_thresh=alpha)\n",
    "    SG.create_subgraph()\n",
    "    SG.select_viable_start_nodes()\n",
    "    x.append(alpha)\n",
    "    y.append(len(SG.start_nodes))\n",
    "plt.plot(x,y, color='maroon')\n",
    "plt.xlabel('Alpha (rel. frequency)')\n",
    "plt.ylabel(f\"| S |\")\n",
    "plt.title(\"Size of start node set S' for alpha\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01d7ba-cb38-438a-a07f-a6b826df8050",
   "metadata": {},
   "source": [
    "## Value matrix\n",
    "\n",
    "With the established set of start nodes and the set of jammer nodes, we can now calculate the value matrix for each route against all possible jammer locations.\n",
    "\n",
    "From the total set of generated routes it shows that the maximum distance is 760 mtr. To err on the side of caution, we assume that the maximum length of a route may add up to 1000 mtrs, so with 240 mtrs margin from the calculated set.\n",
    "\n",
    "For lexicographic ordering, we need to find the proper $\\gamma$ which will allow sufficient resolution between the probability steps to also account for the distance. In the paper, we included eq. 11 to calculate the value of $\\gamma$ for the desired resolution of probability and the expected maximum path length (here: 1000 mtrs) as follows:\n",
    "\n",
    "\\begin{equation} \n",
    "    \\gamma_{0.01} > \\frac{\\Delta L(p)}{\\delta R(P)} = \\frac{6}{0.01} = 600\n",
    "\\end{equation}\n",
    "\n",
    "which gives us:\n",
    "\\begin{equation} \n",
    "    \\gamma_{0.01} > \\frac{\\Delta L(p)}{\\delta R(P)} = \\frac{1000}{0.01} = 100.000\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6411c4-9883-465d-acae-c362361ff108",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.002        #for which we know we'll get 10 start nodes at the edges of the subgraph\n",
    "gamma = 1000 / 0.01  # with max length = 1000 and prob resolution = 0.01\n",
    "battery = 1000       # max distance a drone flies with single battery charge\n",
    "k = 10\n",
    "\n",
    "SG = SubgraphGameOfDrones(GT.G, \n",
    "                          target_node=518, k_hops=6, \n",
    "                          node_importance_dict=rel_node_imp, \n",
    "                          jammer_nodes=jammer_nodes, \n",
    "                          alpha_thresh=alpha)\n",
    "\n",
    "# find the all nodes at max 6 hops from the target\n",
    "SG.create_subgraph()\n",
    "SG.select_viable_start_nodes()\n",
    "\n",
    "print(f\"Start nodes for alpha={alpha} are: {SG.start_nodes}\")\n",
    "\n",
    "# use the set of 10 jammer nodes to generate 5 routes per node.\n",
    "SG.generate_k_shortest_routes(k)\n",
    "\n",
    "# generate the threat model, based on the reduced jammer node set J' but keep the original probs:\n",
    "TM = threat_model(SG.subgraph, jammer_nodes, probs)\n",
    "\n",
    "SG.compute_route_value_matrix(TM)\n",
    "SG.compute_normalised_scalar_payoff_matrix(gamma=gamma, battery_limit=battery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab68c9a-152a-48e6-9c14-64a1e46f36ca",
   "metadata": {},
   "source": [
    "## Risk probability distribution\n",
    "\n",
    "With the attribuut 'route_value_matrix' is it possible to plot the risk probability distribution for the class SubgraphGameOfDrones. The following code counts the risk levels across all route-node pairs and plots these as a scatter plot. Important to see that many routes seem high in risk (lower right hand in the graph) but we still have many routes which have low (2900 with p=0, 2500 with p=2500+ etc in the upper left hand corner.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cde40-a06d-487d-a339-49a212487092",
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = [pair['risk'] for pair in SG.route_value_matrix]\n",
    "risks_counter = Counter(risks)\n",
    "\n",
    "for risk in risks_counter:\n",
    "   plt.scatter(risk, risks_counter[risk], marker='^', color='maroon')\n",
    "plt.grid()\n",
    "plt.xlabel('Route risk probability')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "nr_routes = (len(SG.routes)-1)*len(SG.routes[SG.start_nodes[0]])\n",
    "plt.title(f'Counter for route risk over \\n m={nr_routes} routes and n={len(SG.jammer_nodes)} jammer nodes')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aaa561-a397-4a60-a478-30f91b8f0f9f",
   "metadata": {},
   "source": [
    "## Dominant routes\n",
    "\n",
    "Even the subgraph still has many routes as we selected the 10 most likely start nodes for which we generated the 10 (k=10) 'k_shortest_routes' to the target. With the set of 100 routes and the 10 most likely jammer nodes, we have 1000 route-node pairs. \n",
    "\n",
    "The next step would be to analyse all possible routes for dominance over any of the other ones. This analysis is based on a step by step iteration where for each iteration, all routes and their route-node pairs are compared to the rest of the set of routes. We only consider 'strict domination' before eliminating a dominated route from the set.\n",
    "\n",
    "The removal of dominated routes may change the domination relationship within the set, so we'll repeat the interative process until no dominated routes are found anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544477e6-8f9c-4d05-923d-e90f2ef6b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def iterative_dominance_elimination(payoff_matrix):\n",
    "    current_matrix = payoff_matrix.copy()\n",
    "    route_indices = list(range(current_matrix.shape[0]))  # tracks route indices after pruning\n",
    "\n",
    "    all_domination_records = []  # list of tuples: (dominator_idx_in_full, dominated_idx_in_full)\n",
    "\n",
    "    while True:\n",
    "        nr_routes, nr_nodes = current_matrix.shape\n",
    "        dom_matrix = np.zeros((nr_routes, nr_routes), dtype=int)\n",
    "\n",
    "        # Compute domination matrix for current payoff matrix\n",
    "        for i in range(nr_routes):\n",
    "            for j in range(nr_routes):\n",
    "                if i != j and np.all(current_matrix[i] > current_matrix[j]):\n",
    "                    dom_matrix[i, j] = 1\n",
    "\n",
    "        dominated_local = np.where(np.any(dom_matrix == 1, axis=0))[0]\n",
    "\n",
    "        if len(dominated_local) == 0:\n",
    "            break  # no more dominated routes\n",
    "\n",
    "        # Map local indices to full matrix indices\n",
    "        dominated_full = [route_indices[idx] for idx in dominated_local]\n",
    "        for i_local in range(dom_matrix.shape[0]):\n",
    "            for j_local in dominated_local:\n",
    "                if dom_matrix[i_local, j_local] == 1:\n",
    "                    all_domination_records.append((route_indices[i_local], route_indices[j_local]))\n",
    "\n",
    "        # Remove dominated strategies\n",
    "        keep_mask = np.ones(nr_routes, dtype=bool)\n",
    "        keep_mask[dominated_local] = False\n",
    "        current_matrix = current_matrix[keep_mask, :]\n",
    "        route_indices = [r for i, r in enumerate(route_indices) if keep_mask[i]]\n",
    "\n",
    "    return route_indices, all_domination_records\n",
    "\n",
    "\n",
    "def group_dominations(domination_records):\n",
    "    grouped = defaultdict(list)\n",
    "    for dom, sub in domination_records:\n",
    "        grouped[dom].append(sub)\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def analyze_and_report_dominance(payoff_matrix):\n",
    "    survivors, domination_log = iterative_dominance_elimination(payoff_matrix)\n",
    "    table = group_dominations(domination_log)\n",
    "    return survivors, domination_log\n",
    "\n",
    "\n",
    "drone_action_space, domination_log = analyze_and_report_dominance(SG.normalised_scalar_payoff_matrix)\n",
    "print(drone_action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b79c8-85d5-470e-8ddb-d5f50424a496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now  generate the data for the domination table\n",
    "def group_dominations_from_survivors(domination_log, survivors):\n",
    "    from collections import defaultdict\n",
    "    survivors_set = set(survivors)\n",
    "    table = defaultdict(list)\n",
    "    for dom, sub in domination_log:\n",
    "        if dom in survivors_set:\n",
    "            table[dom].append(sub)\n",
    "    return table\n",
    "\n",
    "\n",
    "\n",
    "# use filtered_table to generate the domination table in the paper.\n",
    "filtered_table = group_dominations_from_survivors(domination_log, drone_action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5511ca-f50f-4dfe-8b8f-04b635f1dce0",
   "metadata": {},
   "source": [
    "# Payoff Matrix\n",
    "\n",
    "In previous sections we've calculated the action space for the drone ('drone_action_space'), the reduced set of routes after dominated routes have been removed. In addition, we also have the set of jammer nodes ('jammer_nodes').\n",
    "\n",
    "We'll create a new class which gets both sets and generates the actual payoff matrix, which we will use for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ffcf29-a944-49aa-b4ee-544f9c62af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "\n",
    "\n",
    "class payoff_matrix():\n",
    "\n",
    "    def __init__(self, drone_actions, jammer_actions, value_matrix):\n",
    "        \"\"\"\n",
    "        Defines the class for the payoff matrix, includes methods to analyse\n",
    "        the game by looking at equilibria, saddle points, mixed strategies\n",
    "        etc, where applicable\n",
    "        \"\"\"\n",
    "        self.payoff = pd.DataFrame(value_matrix[drone_actions],\n",
    "                                   index = drone_actions,\n",
    "                                   columns = jammer_nodes)\n",
    "        print(f\"Payoff matrix | created with shape {self.payoff.shape}\")\n",
    "\n",
    "    def find_pure_nash_equilibrium(self):\n",
    "        \"\"\"\n",
    "        Finds pure strategy Nash equilibria in a zero-sum game.\n",
    "        Returns a list of (drone_action, jammer_action) tuples.\n",
    "        \"\"\"\n",
    "        # Find row minima (best for drone when jammer picks each column)\n",
    "        row_min = self.payoff.min(axis=1)\n",
    "        # Find column maxima (best for jammer when drone picks each row)\n",
    "        col_max = self.payoff.max(axis=0)\n",
    "        \n",
    "        # Find saddle points (simultaneous row minima and column maxima)\n",
    "        nash_eq = []\n",
    "        for drone_action in self.payoff.index:\n",
    "            for jammer_action in self.payoff.columns:\n",
    "                value = self.payoff.loc[drone_action, jammer_action]\n",
    "                if (value == row_min[drone_action] and \n",
    "                    value == col_max[jammer_action]):\n",
    "                    nash_eq.append((drone_action, jammer_action))\n",
    "        \n",
    "        return nash_eq\n",
    "    \n",
    "    def solve_mixed_strategies(self):\n",
    "        \"\"\"\n",
    "        Robust implementation of mixed strategy solver for zero-sum games\n",
    "        Returns:\n",
    "        - drone_strat: Optimal strategy for drone player\n",
    "        - jammer_strat: Optimal strategy for jammer player\n",
    "        - game_value: Value of the game\n",
    "        \"\"\"\n",
    "        A = self.payoff.values\n",
    "        m, n = A.shape  # m drone actions, n jammer actions\n",
    "        \n",
    "        # Shift payoffs to be positive (doesn't affect optimal strategies)\n",
    "        A_shifted = A - np.min(A) + 1\n",
    "        \n",
    "        try:\n",
    "            # ===== Solve for drone's strategy (maximin) =====\n",
    "            # Maximize v subject to A.T @ p >= v\n",
    "            c = np.zeros(m + 1)\n",
    "            c[-1] = -1  # Minimize -v (equivalent to maximizing v)\n",
    "            \n",
    "            # Constraints: A_shifted.T @ p >= v\n",
    "            # Reformulated as: -A_shifted.T @ p + v <= 0\n",
    "            A_ub = np.hstack([-A_shifted.T, np.ones((n, 1))])\n",
    "            b_ub = np.zeros(n)\n",
    "            \n",
    "            # Probability sum constraint: sum(p) = 1\n",
    "            A_eq = np.zeros((1, m + 1))\n",
    "            A_eq[0, :m] = 1\n",
    "            b_eq = np.array([1])\n",
    "            \n",
    "            bounds = [(0, None) for _ in range(m)] + [(None, None)]\n",
    "            \n",
    "            res = linprog(c, A_ub=A_ub, b_ub=b_ub,\n",
    "                         A_eq=A_eq, b_eq=b_eq,\n",
    "                         bounds=bounds,\n",
    "                         method='highs')\n",
    "            \n",
    "            if not res.success:\n",
    "                raise ValueError(\"Drone strategy optimization failed\")\n",
    "                \n",
    "            drone_probs = res.x[:m]\n",
    "            game_value_shifted = res.x[-1]\n",
    "            \n",
    "            # ===== Solve for jammer's strategy (minimax) =====\n",
    "            # Minimize v subject to A @ q <= v\n",
    "            c = np.zeros(n + 1)\n",
    "            c[-1] = 1  # Minimize v\n",
    "            \n",
    "            # Constraints: A_shifted @ q <= v\n",
    "            A_ub = np.hstack([A_shifted, -np.ones((m, 1))])\n",
    "            b_ub = np.zeros(m)\n",
    "            \n",
    "            # Probability sum constraint: sum(q) = 1\n",
    "            A_eq = np.zeros((1, n + 1))\n",
    "            A_eq[0, :n] = 1\n",
    "            b_eq = np.array([1])\n",
    "            \n",
    "            res = linprog(c, A_ub=A_ub, b_ub=b_ub,\n",
    "                         A_eq=A_eq, b_eq=b_eq,\n",
    "                         bounds=bounds[:n+1],\n",
    "                         method='highs')\n",
    "            \n",
    "            if not res.success:\n",
    "                raise ValueError(\"Jammer strategy optimization failed\")\n",
    "                \n",
    "            jammer_probs = res.x[:n]\n",
    "            \n",
    "            # ===== Convert back to original payoff scale =====\n",
    "            game_value = game_value_shifted + np.min(A) - 1\n",
    "            \n",
    "            # ===== Create probability distributions =====\n",
    "            # Filter out near-zero probabilities\n",
    "            drone_probs = np.where(drone_probs < 1e-6, 0, drone_probs)\n",
    "            jammer_probs = np.where(jammer_probs < 1e-6, 0, jammer_probs)\n",
    "            \n",
    "            # Normalize\n",
    "            drone_probs = drone_probs / np.sum(drone_probs)\n",
    "            jammer_probs = jammer_probs / np.sum(jammer_probs)\n",
    "            \n",
    "            drone_strat = pd.Series(drone_probs, index=self.payoff.index, name=\"Drone\")\n",
    "            jammer_strat = pd.Series(jammer_probs, index=self.payoff.columns, name=\"Jammer\")\n",
    "            \n",
    "            return drone_strat, jammer_strat, game_value\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Optimization error: {str(e)}\")\n",
    "            print(\"Falling back to iterative method...\")\n",
    "            \n",
    "            # Fallback to fictitious play approximation\n",
    "            return self.approximate_mixed_strategies()\n",
    "    \n",
    "    def approximate_mixed_strategies(self, iterations=1000):\n",
    "        \"\"\"Fictitious play approximation when LP fails\"\"\"\n",
    "        A = self.payoff.values\n",
    "        m, n = A.shape\n",
    "        \n",
    "        # Initialize strategies uniformly\n",
    "        drone_strat = np.ones(m)/m\n",
    "        jammer_strat = np.ones(n)/n\n",
    "        \n",
    "        # Fictitious play iteration\n",
    "        for _ in range(iterations):\n",
    "            # Jammer best response to current drone strategy\n",
    "            jammer_br = np.zeros(n)\n",
    "            jammer_br[np.argmin(A.T @ drone_strat)] = 1\n",
    "            \n",
    "            # Drone best response to current jammer strategy\n",
    "            drone_br = np.zeros(m)\n",
    "            drone_br[np.argmax(A @ jammer_strat)] = 1\n",
    "            \n",
    "            # Update strategies\n",
    "            drone_strat = (drone_strat * _ + drone_br) / (_ + 1)\n",
    "            jammer_strat = (jammer_strat * _ + jammer_br) / (_ + 1)\n",
    "        \n",
    "        # Calculate game value\n",
    "        game_value = drone_strat @ A @ jammer_strat\n",
    "        \n",
    "        # Create pandas Series\n",
    "        drone_series = pd.Series(drone_strat, index=self.payoff.index, name=\"Drone\")\n",
    "        jammer_series = pd.Series(jammer_strat, index=self.payoff.columns, name=\"Jammer\")\n",
    "        \n",
    "        return drone_series, jammer_series, game_value\n",
    "\n",
    "    \n",
    "    def analyze_game(self):\n",
    "        \"\"\"Convenience method to run both analyses\"\"\"\n",
    "        print(\"=== Pure Strategy Nash Equilibrium ===\")\n",
    "        nash_eq = self.find_pure_nash_equilibrium()\n",
    "        if nash_eq:\n",
    "            for eq in nash_eq:\n",
    "                print(f\"Drone action: {eq[0]}, Jammer action: {eq[1]}\")\n",
    "                print(f\"Payoff value: {self.payoff.loc[eq[0], eq[1]]:.4f}\")\n",
    "        else:\n",
    "            print(\"No pure strategy Nash equilibrium found\")\n",
    "        \n",
    "        print(\"\\n=== Optimal Mixed Strategies ===\")\n",
    "        drone_strat, jammer_strat, value = self.solve_mixed_strategies()\n",
    "        print(f\"Game value: {value:.4f}\")\n",
    "        \n",
    "        print(\"\\nDrone optimal strategy:\")\n",
    "        print(drone_strat[drone_strat > 1e-6].round(4))  # Show non-zero probabilities\n",
    "        \n",
    "        print(\"\\nJammer optimal strategy:\")\n",
    "        print(jammer_strat[jammer_strat > 1e-6].round(4))  # Show non-zero probabilities\n",
    "                                    \n",
    "\n",
    "PM = payoff_matrix(drone_action_space, jammer_nodes, SG.normalised_scalar_payoff_matrix)\n",
    "PM.payoff.round(2)\n",
    "PM.analyze_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64d40b-2a07-4739-b208-03cffa0208de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a specified route (list of node IDs) on the shared ax\n",
    "\n",
    "def plot_graph_routes_jammer_nodes(graph, routes, jammer_nodes, target=518):\n",
    "\n",
    "    fig, ax = ox.plot_graph(graph, figsize=(12, 10), node_size=10, show=False, close=False)\n",
    "    \n",
    "    for route, color, label in zip(routes, ['orange', 'yellow'], ['Route81', 'Route90']):\n",
    "        # Extract coordinates\n",
    "        x = [graph.nodes[node]['x'] for node in route]\n",
    "        y = [graph.nodes[node]['y'] for node in route]\n",
    "        \n",
    "        # Plot the route on the existing axis\n",
    "        ax.plot(x, y, color=color, linewidth=4, zorder=4)\n",
    "        ax.scatter(x, y, color=color, s=50, zorder=4, label=label)\n",
    "        \n",
    "        # Optionally highlight start and end\n",
    "        ax.scatter(x[0], y[0], color='green', s=30, zorder=5, label='start nodes')  # start node\n",
    "        ax.text(x[0]-0.0005, y[0]+0.0002, s=f\"V={route[0]}\", color=color)\n",
    "        ax.scatter(x[-1], y[-1], color='red', s=30, zorder=5)  # end node\n",
    "\n",
    "    # plot both jammer nodes in maroon\n",
    "    for node in jammer_nodes:\n",
    "        ax.scatter(graph.nodes[node]['x'], graph.nodes[node]['y'], color='maroon', s=50, zorder=5, label='jammer node')\n",
    "        ax.text(graph.nodes[node]['x']-0.0005, graph.nodes[node]['y']-0.0003, s=f\"J={node}\", color='white')\n",
    "\n",
    "    # now show target as larger bright red circle behind the routes and jammer nodes\n",
    "    ax.scatter(graph.nodes[target]['x'], graph.nodes[target]['y'], color='red', s=250, zorder=3, label='target @ node518')\n",
    "    ax.text(graph.nodes[target]['x']-0.0005, graph.nodes[target]['y']+0.0003, s=f\"T={target}\", color='red')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('GoD_endgame.png')\n",
    "\n",
    "\n",
    "Route81 = [319, 444, 443, 442, 518]\n",
    "Route90 = [504, 539, 409, 553, 610, 517, 518]\n",
    "plot_graph_routes_jammer_nodes(SG.subgraph, [Route81, Route90], [518, 517])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c163e45-4b75-42cf-b944-816e34876654",
   "metadata": {},
   "outputs": [],
   "source": [
    "PM.payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c07e9-7b40-4817-816a-3857ab016335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b62fc-4fa6-4d73-83dc-fecb3d90b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the domain\n",
    "x = np.linspace(0, 1, 500)\n",
    "\n",
    "# Correct payoff values from user-provided matrix\n",
    "A_81_518 = -0.721996\n",
    "A_81_517 = -0.541402\n",
    "A_90_518 = -0.721853\n",
    "A_90_517 = -0.838336\n",
    "A_30_518 = -0.748609\n",
    "A_30_517 = -0.830554\n",
    "\n",
    "# Expected utilities as functions of jammer strategy\n",
    "u_81 = A_81_518 * x + A_81_517 * (1 - x)\n",
    "u_90 = A_90_518 * x + A_90_517 * (1 - x)\n",
    "u_30 = A_30_518 * x + A_30_517 * (1 - x)\n",
    "\n",
    "# Pointwise maximum of the two (value to the drone)\n",
    "game_value = np.maximum(u_81, u_90)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, u_81, label=r'$u_{81}(x) = -0.18x - 0.54$', color='blue')\n",
    "plt.plot(x, u_90, label=r'$u_{90}(x) = 0.12x - 0.84$', color='green')\n",
    "plt.plot(x, u_30, label=r'$u_{30}(x) = 0.08x - 0.83$', color='maroon', linestyle=':')\n",
    "plt.plot(x, game_value, label='Game Value', color='black', linestyle='--')\n",
    "\n",
    "# Mark the intersection (saddle point)\n",
    "intersection_x = (A_90_517 - A_81_517) / ((A_81_518 - A_81_517) + (A_90_517 - A_90_518))\n",
    "intersection_y = A_81_518 * intersection_x + A_81_517 * (1 - intersection_x)\n",
    "plt.plot(intersection_x, intersection_y, 'ro', label='Saddle Point')\n",
    "print(intersection_x, intersection_y)\n",
    "\n",
    "plt.title(\"Expected Drone Payoff vs. Jammer Mixed Strategy\")\n",
    "plt.xlabel(\"Probability of jammer choosing node 518\")\n",
    "plt.ylabel(\"Expected payoff to drone\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "image_path = \"saddle_point_plot_Tilburg map.png\"\n",
    "plt.savefig(image_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c9343-d5fb-4889-960a-c01d1bc234e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the domain\n",
    "x = np.linspace(0, 1, 500)\n",
    "\n",
    "# Correct payoff values from user-provided matrix\n",
    "A_518_81 = -0.721996\n",
    "A_518_90 = -0.721853\n",
    "A_517_81 = -0.541402\n",
    "A_517_90 = -0.838336\n",
    "\n",
    "# Expected utilities as functions of jammer strategy\n",
    "u_518 = A_518_81 * x + (1-x) * A_518_90\n",
    "u_517 = A_517_81 * x + (1-x) * A_517_90\n",
    "\n",
    "\n",
    "# Pointwise maximum of the two (value to the drone)\n",
    "game_value = np.maximum(u_518, u_517)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, u_517, label=r'$u_{517}(x) = -0.297x - 0.84$', color='blue')\n",
    "plt.plot(x, u_518, label=r'$u_{518}(x) = 0.001x - 0.72$', color='green')\n",
    "plt.plot(x, game_value, label='Game Value', color='black', linestyle='--')\n",
    "\n",
    "# Mark the intersection (saddle point)\n",
    "intersection_x = .3902\n",
    "intersection_y = A_518_81 * intersection_x + (1-intersection_x)*A_518_90\n",
    "plt.plot(intersection_x, intersection_y, 'ro', label='Saddle Point')\n",
    "print(intersection_x, intersection_y)\n",
    "\n",
    "plt.title(\"Expected Jammer Payoff vs. Drone Mixed Strategy\")\n",
    "plt.xlabel(\"Probability of drone choosing route 81\")\n",
    "plt.ylabel(\"Expected payoff to jammer\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "image_path = \"saddle_point_plot_Tilburg map_drone.png\"\n",
    "plt.savefig(image_path, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3cc8e-f6fb-4dd4-b515-fb435986506f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (phd_research)",
   "language": "python",
   "name": "phd_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
